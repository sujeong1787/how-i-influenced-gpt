# Tool Explanation Feedback

## Summary
I gave repeated feedback about the lack of clarity and usability in GPT’s tool-related features, specifically web search and summarization tools. I requested clearer guidance on what each tool does, how and when it activates, and how the results are structured. I also provided suggestions on how to make tool outputs more readable and contextually appropriate.

## Key Feedback Dates
- **2025-03-05:** Noted insufficient explanation when a tool was invoked (e.g., web, summarization)
- **2025-03-08:** Suggested pre-response notices about tool use (e.g., “I’ll look that up for you”)
- **2025-04-11:** Proposed that tool outputs be presented more clearly, especially in mobile view
- **2025-04-14:** Recommended separating conflicting perspectives instead of merging them in summaries

## Feedback Details
- Asked for brief yet consistent descriptions of tool behavior when used in a conversation
- Criticized abrupt or context-less insertion of tool outputs
- Highlighted how some summaries felt oversimplified or distorted due to forced merging
- Suggested a more neutral layout for presenting multiple viewpoints

## Resulting Changes
- GPT began providing clearer, sentence-level preambles when tools were used
- Summaries became more segmented when topics were controversial or ambiguous
- Layout of tool results improved in mobile responses (visually clearer, less compressed)

## Significance
Tool usage is one of the most powerful features of GPT—but only when users know what’s happening. This case shows how small changes in explanation and structure can significantly improve user trust and comprehension, especially for high-context tasks like summarization or search.

